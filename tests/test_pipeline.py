"""
Pipeline RAG interactivo: escribe tu pregunta y ve el proceso completo.

Ejecutar:
    python tests/test_pipeline.py
"""
from __future__ import annotations

import sys
from pathlib import Path

# Agregar raÃ­z del proyecto al PYTHONPATH
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from typing import Any, Dict, List

from src.oraculo.config import get_settings
from src.oraculo.providers.query_refiner import refine_user_question
from src.oraculo.rag.doc_context import build_doc_contexts_from_hits
from src.oraculo.rag.prompting import build_answer_prompt_from_doc_contexts
from src.oraculo.rag.retriever import retrieve
from src.oraculo.providers.llm import generate_answer
from src.oraculo.sources.resolver import format_sources_from_hits


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Utilidades de impresiÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SEP = "=" * 80
SUBSEP = "-" * 70


def _header(title: str) -> None:
    print(f"\n{SEP}\n  {title}\n{SEP}")


def _subheader(title: str) -> None:
    print(f"\n{SUBSEP}\n  {title}\n{SUBSEP}")


def _print_hits(hits: List[Dict[str, Any]], max_text: int = 150) -> None:
    print(f"\n  Total: {len(hits)} documentos recuperados\n")
    for i, h in enumerate(hits, 1):
        score = h.get("score", 0.0)
        p = h.get("payload", {})
        doc_id = p.get('doc_id', '?')
        especie = p.get('especie', '')
        producto = p.get('producto', '')
        variedad = p.get('variedad', '')
        text = p.get('text', '')[:max_text].replace('\n', ' ')
        
        print(f"  [{i:>2}] Score: {score:.4f}")
        print(f"       Doc ID: {doc_id}")
        print(f"       Especie: {especie}  |  Producto: {producto}  |  Variedad: {variedad}")
        print(f"       Snippet: {text}...")
        print()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pipeline interactivo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_interactive_pipeline():
    """
    Pipeline interactivo que solicita la pregunta al usuario y muestra:
      1. Pregunta original
      2. Consulta optimizada (refinada)
      3. InformaciÃ³n del RAG (hits recuperados)
      4. Respuesta final redactada por el LLM
    """
    settings = get_settings()
    
    print("\n" + "â–ˆ" * 80)
    print("  SISTEMA RAG INTERACTIVO - ORÃCULO AGRÃ“NOMO")
    print("â–ˆ" * 80)
    print("\n  Escribe tu pregunta sobre ensayos agronÃ³micos.")
    print("  (Ejemplos: productos para araÃ±ita roja en cerezo, para quÃ© sirve Kelpak, etc.)")
    print()
    
    # Solicitar pregunta al usuario
    question = input("  ğŸ” Tu pregunta: ").strip()
    
    if not question:
        print("\n  âš ï¸  No se ingresÃ³ ninguna pregunta. Saliendo...")
        return
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 1: Mostrar pregunta original
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    _header("1ï¸âƒ£  PREGUNTA ORIGINAL")
    print(f"\n  {question}\n")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 2: Optimizar consulta con Gemini
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    _header("2ï¸âƒ£  CONSULTA OPTIMIZADA PARA BÃšSQUEDA")
    print("\n  â³ Optimizando consulta con Gemini...\n")
    
    rewritten_query = refine_user_question(question, settings)
    
    print(f"  {rewritten_query}\n")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 3: Recuperar informaciÃ³n del RAG
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    _header("3ï¸âƒ£  INFORMACIÃ“N RECUPERADA DEL RAG")
    print("\n  â³ Buscando documentos relevantes en Qdrant...\n")
    
    rewritten2, hits = retrieve(question, settings, top_k=8)
    
    _print_hits(hits)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASO 4: Construir contexto y generar respuesta con LLM
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    _header("4ï¸âƒ£  RESPUESTA REDACTADA CON LA INFORMACIÃ“N")
    print("\n  â³ Generando respuesta con Gemini...\n")
    
    # Construir contexto por documento
    doc_contexts = build_doc_contexts_from_hits(hits, settings)
    
    # Construir prompt
    prompt = build_answer_prompt_from_doc_contexts(
        question=question,
        refined_question=rewritten_query,
        doc_contexts=doc_contexts,
    )
    
    # Generar respuesta con LLM
    llm_output = generate_answer(prompt, settings, system_instruction="")
    
    # Agregar fuentes
    sources_block = format_sources_from_hits(hits)
    
    final_answer = llm_output.rstrip()
    if sources_block:
        final_answer = final_answer + "\n\n" + sources_block
    
    print(f"{final_answer}\n")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Resumen final
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print(f"\n{SUBSEP}")
    print(f"  âœ… Respuesta generada exitosamente")
    print(f"  ğŸ“Š Documentos consultados: {len(hits)}")
    print(f"  ğŸ“„ Informes procesados: {len(doc_contexts)}")
    print(f"  ğŸ“ Caracteres en respuesta: {len(final_answer)}")
    print(f"{SUBSEP}\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EjecuciÃ³n directa
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    try:
        run_interactive_pipeline()
    except KeyboardInterrupt:
        print("\n\n  âš ï¸  Interrumpido por el usuario. Saliendo...")
    except Exception as e:
        print(f"\n\n  âŒ Error: {e}")
        import traceback
        traceback.print_exc()
